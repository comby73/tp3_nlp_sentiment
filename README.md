# üê¶ An√°lisis de Sentimientos en Twitter (Sentiment140)

**Autor:** Omar Alejandro Gonz√°lez  
**Diplomatura en Inteligencia Artificial - Universidad de Palermo**  
**Trabajo Pr√°ctico 3 - NLP**

---

## üìå Descripci√≥n del Proyecto

Este proyecto implementa un pipeline completo de **Procesamiento de Lenguaje Natural (NLP)** para clasificar el sentimiento de tweets como **Positivo** o **Negativo**, utilizando el dataset **Sentiment140** (1.6 millones de tweets).

El desarrollo sigue la metodolog√≠a **CRISP-DM** y est√° estructurado en notebooks modulares que cubren desde el an√°lisis exploratorio hasta la comparaci√≥n con modelos pre-entrenados de la industria.

---

## üìä Dataset

| Caracter√≠stica | Valor |
|----------------|-------|
| **Nombre** | Sentiment140 |
| **Tama√±o** | 1,600,000 tweets |
| **Clases** | Binario (0=Negativo, 4=Positivo) |
| **Balance** | 50% / 50% (perfectamente balanceado) |
| **Periodo** | Abril - Junio 2009 |
| **Fuente** | [Sentiment140](http://help.sentiment140.com/for-students) |

> **Nota sobre neutrales:** El dataset de entrenamiento NO contiene tweets neutrales. Los 139 tweets neutrales del conjunto de test fueron excluidos para mantener coherencia metodol√≥gica.

---

## üèÜ Resultados Destacados

### Modelo Final: Linear SVM

| M√©trica | Valor |
|---------|-------|
| **F1-Score** | **85.18%** |
| **Accuracy** | 84.68% |
| **Precision** | 85.07% |

| Modelo | Accuracy | Velocidad | Tipo |
|--------|----------|-----------|------|
| **Nuestro SVM** | 84.68% | ‚ö° Muy r√°pida | Entrenado espec√≠ficamente |
| TextBlob | ~65% | ‚ö° R√°pida | Basado en reglas |
| VADER | ~71% | ‚ö° R√°pida | Optimizado para redes sociales |
| BERT (RoBERTa) | **94.57%** | üê¢ Lenta (50x) | Transformer pre-entrenado |

> **Decisi√≥n:** Se eligi√≥ Linear SVM porque es **49x m√°s r√°pido** que BERT con performance competitiva, ideal para entornos productivos con recursos est√°ndar.

---

## üìÇ Estructura del Proyecto
```
tp3_nlp_sentiment/
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îú‚îÄ‚îÄ predictions/            # Predicciones generadas
‚îÇ   ‚îú‚îÄ‚îÄ processed/              # Datos limpios (CSV)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Datasets originales
‚îÇ   ‚îî‚îÄ‚îÄ vectorized/             # Matrices TF-IDF (.pkl)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ models/
‚îÇ   ‚îú‚îÄ‚îÄ best_model_linear_svm.pkl
‚îÇ   ‚îú‚îÄ‚îÄ model_metrics.pkl
‚îÇ   ‚îî‚îÄ‚îÄ word2vec_model.pkl
‚îÇ
‚îú‚îÄ‚îÄ üìÅ notebooks/               # 11 notebooks (01-11)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ reports/
‚îÇ   ‚îú‚îÄ‚îÄ figuras/                # Visualizaciones generadas
‚îÇ   ‚îú‚îÄ‚îÄ eda_summary.json
‚îÇ   ‚îî‚îÄ‚îÄ informe_tp3.md
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/                     # M√≥dulos Python reutilizables
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ data_loading.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py
‚îÇ   ‚îú‚îÄ‚îÄ features.py
‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îî‚îÄ‚îÄ visualization.py
‚îÇ
‚îú‚îÄ‚îÄ üìÅ tests/                   # Tests unitarios
‚îú‚îÄ‚îÄ predict_sentiment.py        # Script de predicci√≥n standalone
‚îú‚îÄ‚îÄ requirements.txt            # Dependencias
‚îî‚îÄ‚îÄ README.md
```
---

## üî¨ Metodolog√≠a (CRISP-DM)

### 1. Comprensi√≥n de los Datos (`01_eda.ipynb`)
- An√°lisis de distribuci√≥n de clases (50/50 balanceado)
- Estad√≠sticas de longitud de tweets
- WordClouds por polaridad
- Identificaci√≥n de elementos: URLs (5.1%), Mentions (46.2%), Hashtags (2.2%)

### 2. Preparaci√≥n de Datos (`02_preprocessing.ipynb`)
- Eliminaci√≥n de URLs, mentions
- Conversi√≥n de hashtags a texto (#fail ‚Üí fail)
- Normalizaci√≥n de caracteres repetidos (goooood ‚Üí good)
- Extracci√≥n de 8 features num√©ricas
- Verificaci√≥n de data leakage

### 3. Feature Engineering (`03_vectorizacion.ipynb`)
- **TF-IDF** con 10,000 features
- **Bigramas** (ngram_range=(1,2)) para capturar negaciones
- Stopwords personalizadas (conserva "not", "no", "very")
- Matriz sparse eficiente (99.89% sparsity)

### 4. Modelado (`04_modelado.ipynb`)
- Split: Train (85%) / Validaci√≥n (15%) / Test (359 tweets)
- Modelos evaluados: LogReg, SVM, NaiveBayes, RandomForest
- Selecci√≥n por F1-Score
- Re-entrenamiento del mejor modelo con datos completos (Train + Val)
- Verificaci√≥n de Overfitting: Diferencia m√≠nima entre m√©tricas de Train y Test

### 5. Evaluaci√≥n (`05-09`)
- Optimizaci√≥n de hiperpar√°metros (GridSearchCV)
- An√°lisis de errores y confidence scores
- Auditor√≠a de sesgos por longitud y metadatos
- Comparaci√≥n con TextBlob, VADER, BERT

---

## üéÆ Demos Interactivas (Word2Vec)

El proyecto incluye dos juegos que demuestran las capacidades de **Word2Vec** entrenado en los 1.6M tweets:

### Sopa de Letras Sem√°ntica (`10_sopa_letras.ipynb`)
- Encuentra palabras relacionadas sem√°nticamente
- Puntuaci√≥n basada en similitud coseno
- Interfaz biling√ºe (ingl√©s/espa√±ol)

### Word2Vec Tetris (`11_word2vec_tetris.ipynb`)
- Forma palabras en cualquier direcci√≥n
- Detecci√≥n horizontal, vertical y diagonal
- Animaciones de explosi√≥n al formar palabras

> Estos juegos demuestran c√≥mo Word2Vec captura relaciones sem√°nticas: palabras como "happy", "love", "great" aparecen cercanas en el espacio vectorial.

---

## üöÄ Instalaci√≥n y Uso

### Requisitos

```bash
# Dependencias principales
pip install pandas numpy scikit-learn matplotlib seaborn joblib scipy

# Para comparaci√≥n con pre-entrenados
pip install textblob vaderSentiment transformers torch

# Para juegos Word2Vec
pip install gensim
```

### Ejecuci√≥n

1. **Clonar/descargar** el proyecto
2. **Descargar** el dataset Sentiment140 y colocarlo en `data/raw/`
3. **Ejecutar notebooks** en orden num√©rico (01 ‚Üí 11)

```bash
# Para reproducir desde cero:
jupyter notebook notebooks/01_eda.ipynb
```

> **Atajo:** Si solo quieres usar el modelo, los archivos `.pkl` en `models/` permiten saltar directamente al notebook `08_prediccion.ipynb`.

---

## üìà Hallazgos Clave

### Del An√°lisis de Errores
- **Confianza promedio en aciertos:** 0.629
- **Confianza promedio en errores:** 0.300
- Los errores tienden a tener baja confianza (comportamiento esperado)

### Del An√°lisis de Sesgos
- Tweets muy cortos (<50 chars) tienen menor rendimiento
- Tweets con solo URLs o m√∫ltiples mentions son propensos a errores
- El modelo es robusto para tweets de longitud t√≠pica (50-140 chars)

### Del An√°lisis Temporal (Nuevo)
- **Patr√≥n Nocturno:** Se observa una mayor concentraci√≥n de tweets negativos en horas de la madrugada (00:00 - 06:00).
- **Validaci√≥n de Hip√≥tesis:** Confirma la intuici√≥n de que el horario influye en el sentimiento (usuarios m√°s cr√≠ticos/negativos de noche).

### Patrones Dif√≠ciles
- **Negaciones complejas:** "how can you not love..." (positivo pero tiene "not")
- **Sarcasmo/iron√≠a:** Requerir√≠a contexto adicional
- **Jerga de 2009:** Algunas expresiones han cambiado de significado

### Mejoras Futuras Identificadas
Aunque el EDA revel√≥ patrones temporales (madrugada m√°s negativa), **no se incluy√≥ la hora como feature en el modelo final** por las siguientes razones:
1.  **Prioridad del Texto:** El contenido sem√°ntico es el predictor dominante (>95% de la se√±al).
2.  **Complejidad vs Beneficio:** Incorporar la hora requiere *codificaci√≥n c√≠clica* (Seno/Coseno) para evitar distorsiones num√©ricas (23 vs 0), lo cual aumentar√≠a la complejidad del pipeline para una ganancia marginal estimada.
3.  **Estrategia:** Se deja planteado como la principal v√≠a de optimizaci√≥n para una futura iteraci√≥n "v2.0" del modelo.

---

## üõ†Ô∏è Tecnolog√≠as

| Categor√≠a | Herramientas |
|-----------|--------------|
| **Lenguaje** | Python 3.8+ |
| **ML/NLP** | Scikit-Learn, Gensim |
| **Datos** | Pandas, NumPy, SciPy |
| **Visualizaci√≥n** | Matplotlib, Seaborn, Plotly |
| **Pre-entrenados** | TextBlob, VADER, Transformers (BERT) |
| **Persistencia** | Joblib, Pickle |

---

## üìö Referencias

- [Sentiment140 Dataset](http://help.sentiment140.com/for-students)
- [Scikit-Learn Documentation](https://scikit-learn.org/)
- [VADER Sentiment](https://github.com/cjhutto/vaderSentiment)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)

---

## üìù Licencia

Proyecto acad√©mico - Universidad de Palermo
---

## ‚ö†Ô∏è Archivos No Incluidos (por tama√±o)

Los siguientes archivos superan el l√≠mite de GitHub (100MB) y deben descargarse o regenerarse:

| Archivo | Tama√±o | C√≥mo obtenerlo |
|---------|--------|----------------|
| `data/raw/training.1600000.processed.noemoticon.csv` | ~250 MB | [Descargar de Sentiment140](http://help.sentiment140.com/for-students) |
| `data/processed/train_processed.csv` | ~267 MB | Ejecutar `02_preprocessing.ipynb` |
| `data/vectorized/X_train.pkl` | ~210 MB | Ejecutar `03_vectorizacion.ipynb` |

### Pasos para regenerar:
```bash
# 1. Descargar dataset y colocar en data/raw/
# 2. Ejecutar notebooks en orden:
jupyter notebook notebooks/01_eda.ipynb
jupyter notebook notebooks/02_preprocessing.ipynb
jupyter notebook notebooks/03_vectorizacion.ipynb
```
```
