# ðŸ¦ AnÃ¡lisis de Sentimientos en Twitter (Sentiment140)

**Autor:** Omar Alejandro GonzÃ¡lez  
**Diplomatura en Inteligencia Artificial - Universidad de Palermo**  
**Trabajo PrÃ¡ctico 3 - NLP**

---

## ðŸ“Œ DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline completo de **Procesamiento de Lenguaje Natural (NLP)** para clasificar el sentimiento de tweets como **Positivo** o **Negativo**, utilizando el dataset **Sentiment140** (1.6 millones de tweets).

El desarrollo sigue la metodologÃ­a **CRISP-DM** y estÃ¡ estructurado en notebooks modulares que cubren desde el anÃ¡lisis exploratorio hasta la comparaciÃ³n con modelos pre-entrenados de la industria.

---

## ðŸ“Š Dataset

| CaracterÃ­stica | Valor |
|----------------|-------|
| **Nombre** | Sentiment140 |
| **TamaÃ±o** | 1,600,000 tweets |
| **Clases** | Binario (0=Negativo, 4=Positivo) |
| **Balance** | 50% / 50% (perfectamente balanceado) |
| **Periodo** | Abril - Junio 2009 |
| **Fuente** | [Sentiment140](http://help.sentiment140.com/for-students) |

> **Nota sobre neutrales:** El dataset de entrenamiento NO contiene tweets neutrales. Los 139 tweets neutrales del conjunto de test fueron excluidos para mantener coherencia metodolÃ³gica.

---

## ðŸ† Resultados Destacados

### Modelo Final: Linear SVM

| MÃ©trica | Valor |
|---------|-------|
| **F1-Score** | **85.41%** |
| **Accuracy** | 84.96% |
| **Precision** | 85.07% |
| **Recall** | 85.71% |

### ComparaciÃ³n de Modelos Entrenados

| Modelo | F1-Score (Test) | Tiempo | Observaciones |
|--------|-----------------|--------|---------------|
| **Linear SVM** | **0.8541** | ~12s | âœ… **Mejor balance rendimiento/eficiencia** |
| Logistic Regression | 0.8420 | ~15s | Baseline robusto |
| Naive Bayes (Complement) | 0.8180 | ~3s | MÃ¡s rÃ¡pido pero menor performance |
| Random Forest | 0.8150 | ~145s | Costoso computacionalmente |

### ComparaciÃ³n con Modelos Pre-entrenados

| Modelo | Accuracy | Velocidad | Tipo |
|--------|----------|-----------|------|
| **Nuestro SVM** | 84.68% | âš¡ Muy rÃ¡pida | Entrenado especÃ­ficamente |
| TextBlob | ~65% | âš¡ RÃ¡pida | Basado en reglas |
| VADER | ~71% | âš¡ RÃ¡pida | Optimizado para redes sociales |
| BERT (RoBERTa) | **94.57%** | ðŸ¢ Lenta (50x) | Transformer pre-entrenado |

> **DecisiÃ³n:** Se eligiÃ³ Linear SVM porque es **49x mÃ¡s rÃ¡pido** que BERT con performance competitiva, ideal para entornos productivos con recursos estÃ¡ndar.

---

## ðŸ“‚ Estructura del Proyecto
```
tp3_nlp_sentiment/
â”œâ”€â”€ ðŸ“ data/
â”‚   â”œâ”€â”€ predictions/            # Predicciones generadas
â”‚   â”œâ”€â”€ processed/              # Datos limpios (CSV)
â”‚   â”œâ”€â”€ raw/                    # Datasets originales
â”‚   â””â”€â”€ vectorized/             # Matrices TF-IDF (.pkl)
â”‚
â”œâ”€â”€ ðŸ“ models/
â”‚   â”œâ”€â”€ best_model_linear_svm.pkl
â”‚   â”œâ”€â”€ model_metrics.pkl
â”‚   â””â”€â”€ word2vec_model.pkl
â”‚
â”œâ”€â”€ ðŸ“ notebooks/               # 11 notebooks (01-11)
â”‚
â”œâ”€â”€ ðŸ“ reports/
â”‚   â”œâ”€â”€ figuras/                # Visualizaciones generadas
â”‚   â”œâ”€â”€ eda_summary.json
â”‚   â””â”€â”€ informe_tp3.md
â”‚
â”œâ”€â”€ ðŸ“ src/                     # MÃ³dulos Python reutilizables
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ data_loading.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”œâ”€â”€ features.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â””â”€â”€ visualization.py
â”‚
â”œâ”€â”€ ðŸ“ tests/                   # Tests unitarios
â”œâ”€â”€ predict_sentiment.py        # Script de predicciÃ³n standalone
â”œâ”€â”€ requirements.txt            # Dependencias
â””â”€â”€ README.md
```
---

## ðŸ”¬ MetodologÃ­a (CRISP-DM)

### 1. ComprensiÃ³n de los Datos (`01_eda.ipynb`)
- AnÃ¡lisis de distribuciÃ³n de clases (50/50 balanceado)
- EstadÃ­sticas de longitud de tweets
- WordClouds por polaridad
- IdentificaciÃ³n de elementos: URLs (5.1%), Mentions (46.2%), Hashtags (2.2%)

### 2. PreparaciÃ³n de Datos (`02_preprocessing.ipynb`)
- EliminaciÃ³n de URLs, mentions
- ConversiÃ³n de hashtags a texto (#fail â†’ fail)
- NormalizaciÃ³n de caracteres repetidos (goooood â†’ good)
- ExtracciÃ³n de 8 features numÃ©ricas
- VerificaciÃ³n de data leakage

### 3. Feature Engineering (`03_vectorizacion.ipynb`)
- **TF-IDF** con 10,000 features
- **Bigramas** (ngram_range=(1,2)) para capturar negaciones
- Stopwords personalizadas (conserva "not", "no", "very")
- Matriz sparse eficiente (99.89% sparsity)

### 4. Modelado (`04_modelado.ipynb`)
- Split: Train (85%) / ValidaciÃ³n (15%) / Test (359 tweets)
- Modelos evaluados: LogReg, SVM, NaiveBayes, RandomForest
- SelecciÃ³n por F1-Score
- Re-entrenamiento del mejor modelo con datos completos

### 5. EvaluaciÃ³n (`05-09`)
- OptimizaciÃ³n de hiperparÃ¡metros (GridSearchCV)
- AnÃ¡lisis de errores y confidence scores
- AuditorÃ­a de sesgos por longitud y metadatos
- ComparaciÃ³n con TextBlob, VADER, BERT

---

## ðŸŽ® Demos Interactivas (Word2Vec)

El proyecto incluye dos juegos que demuestran las capacidades de **Word2Vec** entrenado en los 1.6M tweets:

### Sopa de Letras SemÃ¡ntica (`10_sopa_letras.ipynb`)
- Encuentra palabras relacionadas semÃ¡nticamente
- PuntuaciÃ³n basada en similitud coseno
- Interfaz bilingÃ¼e (inglÃ©s/espaÃ±ol)

### Word2Vec Tetris (`11_word2vec_tetris.ipynb`)
- Forma palabras en cualquier direcciÃ³n
- DetecciÃ³n horizontal, vertical y diagonal
- Animaciones de explosiÃ³n al formar palabras

> Estos juegos demuestran cÃ³mo Word2Vec captura relaciones semÃ¡nticas: palabras como "happy", "love", "great" aparecen cercanas en el espacio vectorial.

---

## ðŸš€ InstalaciÃ³n y Uso

### Requisitos

```bash
# Dependencias principales
pip install pandas numpy scikit-learn matplotlib seaborn joblib scipy

# Para comparaciÃ³n con pre-entrenados
pip install textblob vaderSentiment transformers torch

# Para juegos Word2Vec
pip install gensim
```

### EjecuciÃ³n

1. **Clonar/descargar** el proyecto
2. **Descargar** el dataset Sentiment140 y colocarlo en `data/raw/`
3. **Ejecutar notebooks** en orden numÃ©rico (01 â†’ 11)

```bash
# Para reproducir desde cero:
jupyter notebook notebooks/01_eda.ipynb
```

> **Atajo:** Si solo quieres usar el modelo, los archivos `.pkl` en `models/` permiten saltar directamente al notebook `08_prediccion.ipynb`.

---

## ðŸ“ˆ Hallazgos Clave

### Del AnÃ¡lisis de Errores
- **Confianza promedio en aciertos:** 0.629
- **Confianza promedio en errores:** 0.300
- Los errores tienden a tener baja confianza (comportamiento esperado)

### Del AnÃ¡lisis de Sesgos
- Tweets muy cortos (<50 chars) tienen menor rendimiento
- Tweets con solo URLs o mÃºltiples mentions son propensos a errores
- El modelo es robusto para tweets de longitud tÃ­pica (50-140 chars)

### Patrones DifÃ­ciles
- **Negaciones complejas:** "how can you not love..." (positivo pero tiene "not")
- **Sarcasmo/ironÃ­a:** RequerirÃ­a contexto adicional
- **Jerga de 2009:** Algunas expresiones han cambiado de significado

---

## ðŸ› ï¸ TecnologÃ­as

| CategorÃ­a | Herramientas |
|-----------|--------------|
| **Lenguaje** | Python 3.8+ |
| **ML/NLP** | Scikit-Learn, Gensim |
| **Datos** | Pandas, NumPy, SciPy |
| **VisualizaciÃ³n** | Matplotlib, Seaborn, Plotly |
| **Pre-entrenados** | TextBlob, VADER, Transformers (BERT) |
| **Persistencia** | Joblib, Pickle |

---

## ðŸ“š Referencias

- [Sentiment140 Dataset](http://help.sentiment140.com/for-students)
- [Scikit-Learn Documentation](https://scikit-learn.org/)
- [VADER Sentiment](https://github.com/cjhutto/vaderSentiment)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)

---

## ðŸ“ Licencia

Proyecto acadÃ©mico - Universidad de Palermo
---

**Â¿Preguntas?** Contactar a Omar GonzÃ¡lez - Diplomatura en IA (UP)