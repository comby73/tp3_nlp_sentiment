# üê¶ An√°lisis de Sentimientos en Twitter (Sentiment140)

**Autor:** Omar Alejandro Gonz√°lez  
**Diplomatura en Inteligencia Artificial - Universidad de Palermo**  
**Trabajo Pr√°ctico 3 - NLP**

---

## üìå Descripci√≥n del Proyecto

Este proyecto implementa un pipeline completo de **Procesamiento de Lenguaje Natural (NLP)** para clasificar el sentimiento de tweets como **Positivo** o **Negativo**, utilizando el dataset **Sentiment140** (1.6 millones de tweets).

El desarrollo sigue la metodolog√≠a **CRISP-DM** y est√° estructurado en notebooks modulares que cubren desde el an√°lisis exploratorio hasta la comparaci√≥n con modelos pre-entrenados de la industria.

---

## üìä Dataset

| Caracter√≠stica | Valor |
|----------------|-------|
| **Nombre** | Sentiment140 |
| **Tama√±o** | 1,600,000 tweets |
| **Clases** | Binario (0=Negativo, 4=Positivo) |
| **Balance** | 50% / 50% (perfectamente balanceado) |
| **Periodo** | Abril - Junio 2009 |
| **Fuente** | [Sentiment140](http://help.sentiment140.com/for-students) |

> **Nota sobre neutrales:** El dataset de entrenamiento NO contiene tweets neutrales. Los 139 tweets neutrales del conjunto de test fueron excluidos para mantener coherencia metodol√≥gica.

---

## üèÜ Resultados Destacados

### Modelo Final: Linear SVM

| M√©trica | Valor |
|---------|-------|
| **F1-Score** | **85.18%** |
| **Accuracy** | 84.68% |
| **Precision** | 85.07% |

| Modelo | Accuracy | Velocidad | Tipo |
|--------|----------|-----------|------|
| **Nuestro SVM** | 84.68% | ‚ö° Muy r√°pida | Entrenado espec√≠ficamente |
| TextBlob | ~65% | ‚ö° R√°pida | Basado en reglas |
| VADER | ~71% | ‚ö° R√°pida | Optimizado para redes sociales |
| BERT (RoBERTa) | **94.57%** | üê¢ Lenta (50x) | Transformer pre-entrenado |

> **Decisi√≥n:** Se eligi√≥ Linear SVM porque es **49x m√°s r√°pido** que BERT con performance competitiva, ideal para entornos productivos con recursos est√°ndar.

---

## üìÇ Estructura del Proyecto
```
tp3_nlp_sentiment/
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îú‚îÄ‚îÄ predictions/            # Predicciones generadas
‚îÇ   ‚îú‚îÄ‚îÄ processed/              # Datos limpios (CSV)
‚îÇ   ‚îú‚îÄ‚îÄ raw/                    # Datasets originales
‚îÇ   ‚îî‚îÄ‚îÄ vectorized/             # Matrices TF-IDF (.pkl)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ models/
‚îÇ   ‚îú‚îÄ‚îÄ best_model_linear_svm.pkl
‚îÇ   ‚îú‚îÄ‚îÄ model_metrics.pkl
‚îÇ   ‚îî‚îÄ‚îÄ word2vec_model.pkl
‚îÇ
‚îú‚îÄ‚îÄ üìÅ notebooks/               # 12 notebooks (01-12)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ reports/
‚îÇ   ‚îú‚îÄ‚îÄ figuras/                # Visualizaciones generadas
‚îÇ   ‚îú‚îÄ‚îÄ dashboard_interactivo.html  # Dashboard con Plotly
‚îÇ   ‚îú‚îÄ‚îÄ eda_summary.json
‚îÇ   ‚îî‚îÄ‚îÄ informe_tp3.md
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/                     # M√≥dulos Python reutilizables
‚îÇ   ‚îú‚îÄ‚îÄ config.py
‚îÇ   ‚îú‚îÄ‚îÄ data_loading.py
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py
‚îÇ   ‚îú‚îÄ‚îÄ features.py
‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îî‚îÄ‚îÄ visualization.py
‚îÇ
‚îú‚îÄ‚îÄ üìÅ tests/                   # Tests unitarios
‚îú‚îÄ‚îÄ predict_sentiment.py        # Script de predicci√≥n standalone
‚îú‚îÄ‚îÄ requirements.txt            # Dependencias
‚îî‚îÄ‚îÄ README.md
```
---

## üî¨ Metodolog√≠a (CRISP-DM)

### 1. Comprensi√≥n de los Datos (`01_eda.ipynb`)
- An√°lisis de distribuci√≥n de clases (50/50 balanceado)
- Estad√≠sticas de longitud de tweets
- WordClouds por polaridad
- Identificaci√≥n de elementos: URLs (5.1%), Mentions (46.2%), Hashtags (2.2%)

### 2. Preparaci√≥n de Datos (`02_preprocessing.ipynb`)
- Eliminaci√≥n de URLs, mentions
- Conversi√≥n de hashtags a texto (#fail ‚Üí fail)
- Normalizaci√≥n de caracteres repetidos (goooood ‚Üí good)
- Extracci√≥n de 8 features num√©ricas
- Verificaci√≥n de data leakage

### 3. Feature Engineering (`03_vectorizacion.ipynb`)
- **TF-IDF** con 10,000 features
- **Bigramas** (ngram_range=(1,2)) para capturar negaciones
- Stopwords personalizadas (conserva "not", "no", "very")
- Matriz sparse eficiente (99.89% sparsity)

### 4. Modelado (`04_modelado.ipynb`)
- Split: Train (85%) / Validaci√≥n (15%) / Test (359 tweets)
- Modelos evaluados: LogReg, SVM, NaiveBayes, RandomForest
- Selecci√≥n por F1-Score
- Re-entrenamiento del mejor modelo con datos completos (Train + Val)
- Verificaci√≥n de Overfitting: Diferencia m√≠nima entre m√©tricas de Train y Test

### 5. Evaluaci√≥n (`05-09`)
- Optimizaci√≥n de hiperpar√°metros (GridSearchCV)
- An√°lisis de errores y confidence scores
- Auditor√≠a de sesgos por longitud y metadatos
- Comparaci√≥n con TextBlob, VADER, BERT

---

## üéÆ Demos Interactivas y Dashboard

El proyecto incluye dos **juegos con generaci√≥n procedural de niveles** y un **dashboard interactivo** que demuestran las capacidades del an√°lisis.

### üìä Dashboard Interactivo (`12_dashboard_interactivo.ipynb`)

Un **dashboard HTML con Plotly** que presenta los resultados m√°s importantes del proyecto:

| Gr√°fico | Descripci√≥n |
|---------|-------------|
| üìà KPIs | Total tweets, features, accuracy, F1-score |
| üèÜ Comparaci√≥n Modelos | 4 modelos con barras agrupadas |
| üìä Features por Polaridad | Boxplots interactivos |
| üé≠ Distribuci√≥n | Pie chart de sentimientos |
| üìè Longitud Tweets | Histogramas superpuestos |
| ‚öñÔ∏è Train vs Test | Comparaci√≥n de caracter√≠sticas |
| üî§ Top Palabras TF-IDF | Por clase positiva/negativa |

**Output:** `reports/dashboard_interactivo.html` - Abre en cualquier navegador, sin servidor.

---

> ‚ö†Ô∏è **Importante:** Los juegos NO son listas fijas de palabras. Son **generadores din√°micos** que construyen cada nivel en tiempo real usando `most_similar()`.

### üî§ Sopa de Letras Sem√°ntica (`10_sopa_letras.ipynb`)

| Caracter√≠stica | Implementaci√≥n |
|----------------|----------------|
| **Generaci√≥n de palabras** | `model_w2v.wv.most_similar(palabra_objetivo)` |
| **Sistema de puntos** | `puntos = similitud_coseno √ó 100` |
| **Dificultad din√°mica** | Basada en distancia sem√°ntica |
| **Interfaz** | Biling√ºe (ingl√©s/espa√±ol) |

**üßÆ Modo Analog√≠as:** El jugador debe encontrar 4 palabras en la sopa y descubrir la analog√≠a algebraica que las conecta (ej: `HAPPY - SAD + GOOD = BAD`).

### üß± Word2Vec Tetris (`11_word2vec_tetris.ipynb`)

| Caracter√≠stica | Implementaci√≥n |
|----------------|----------------|
| **Palabras objetivo** | Top 10 de `most_similar()` |
| **Pool de letras** | Generado din√°micamente seg√∫n palabras similares |
| **Detecci√≥n** | Horizontal + Vertical + Diagonales (4 direcciones) |
| **Feedback visual** | Animaciones de explosi√≥n al formar palabras |
| **Controles** | Teclas A/S/D + botones en pantalla |
| **Game Over** | Pantalla √©pica con efectos visuales |

**üïπÔ∏è Controles:**
- **A** = Mover izquierda ‚¨ÖÔ∏è
- **D** = Mover derecha ‚û°Ô∏è
- **S** = Acelerar ca√≠da ‚¨áÔ∏è

**üåü Bonus de Analog√≠as:** Cuando el jugador forma pares de palabras opuestas (happy-sad, love-hate), el sistema detecta la analog√≠a y otorga +100 pts bonus.

### üß† Motor Sem√°ntico Word2Vec

Cada notebook incluye una **"Calibraci√≥n del Motor Sem√°ntico"** que demuestra las 3 capacidades principales:

```python
# 1. B√∫squeda de palabras similares (most_similar)
>>> model_w2v.wv.most_similar('happy', topn=5)
[('thrilled', 0.62), ('pleased', 0.60), ('sad', 0.59), ...]

# 2. Similitud coseno entre pares de palabras
>>> model_w2v.wv.similarity('love', 'hate')
0.5639  # Cercanas porque co-ocurren en contextos emocionales

# 3. Analog√≠as algebraicas (A - B + C = D)
>>> model_w2v.wv.most_similar(positive=['good', 'sad'], negative=['bad'])
[('happy', 0.57), ...]  # Resuelve: GOOD - BAD + SAD = ?

# 4. Generaci√≥n din√°mica de niveles
>>> # Palabra: 'TWITTER' ‚Üí Nivel: FACEBOOK ‚Üí TUMBLR ‚Üí PLURK
>>> # Palabra: 'MUSIC'   ‚Üí Nivel: TUNES ‚Üí SONGS ‚Üí PLAYLIST
>>> # Palabra: 'FOOD'    ‚Üí Nivel: SNACKS ‚Üí PIZZA ‚Üí SUSHI
```

### üìê Operaciones Vectoriales Demostradas

| Operaci√≥n | Funci√≥n de Gensim | Uso en el Juego |
|-----------|-------------------|-----------------|
| Similitud | `wv.most_similar(palabra)` | Genera palabras del nivel |
| Distancia | `wv.similarity(p1, p2)` | Calcula puntuaci√≥n |
| Analog√≠a | `wv.most_similar(positive=[A,C], negative=[B])` | Bonus de analog√≠as |


## üöÄ Instalaci√≥n y Uso

### Requisitos

```bash
# Dependencias principales
pip install pandas numpy scikit-learn matplotlib seaborn joblib scipy

# Para comparaci√≥n con pre-entrenados
pip install textblob vaderSentiment transformers torch

# Para juegos Word2Vec
pip install gensim
```

### Ejecuci√≥n

1. **Clonar/descargar** el proyecto
2. **Descargar** el dataset Sentiment140 y colocarlo en `data/raw/`
3. **Ejecutar notebooks** en orden num√©rico (01 ‚Üí 12)

```bash
# Para reproducir desde cero:
jupyter notebook notebooks/01_eda.ipynb
```

> **Atajo:** Si solo quieres usar el modelo, los archivos `.pkl` en `models/` permiten saltar directamente al notebook `08_prediccion.ipynb`.

---

## üìà Hallazgos Clave

### Del An√°lisis de Errores
- **Confianza promedio en aciertos:** 0.629
- **Confianza promedio en errores:** 0.300
- Los errores tienden a tener baja confianza (comportamiento esperado)

### Del An√°lisis de Sesgos
- Tweets muy cortos (<50 chars) tienen menor rendimiento
- Tweets con solo URLs o m√∫ltiples mentions son propensos a errores
- El modelo es robusto para tweets de longitud t√≠pica (50-140 chars)

### Del An√°lisis Temporal (Nuevo)
- **Patr√≥n Nocturno:** Se observa una mayor concentraci√≥n de tweets negativos en horas de la madrugada (00:00 - 06:00).
- **Validaci√≥n de Hip√≥tesis:** Confirma la intuici√≥n de que el horario influye en el sentimiento (usuarios m√°s cr√≠ticos/negativos de noche).

### Patrones Dif√≠ciles
- **Negaciones complejas:** "how can you not love..." (positivo pero tiene "not")
- **Sarcasmo/iron√≠a:** Requerir√≠a contexto adicional
- **Jerga de 2009:** Algunas expresiones han cambiado de significado

### Mejoras Futuras Identificadas
Aunque el EDA revel√≥ patrones temporales (madrugada m√°s negativa), **no se incluy√≥ la hora como feature en el modelo final** por las siguientes razones:
1.  **Prioridad del Texto:** El contenido sem√°ntico es el predictor dominante (>95% de la se√±al).
2.  **Complejidad vs Beneficio:** Incorporar la hora requiere *codificaci√≥n c√≠clica* (Seno/Coseno) para evitar distorsiones num√©ricas (23 vs 0), lo cual aumentar√≠a la complejidad del pipeline para una ganancia marginal estimada.
3.  **Estrategia:** Se deja planteado como la principal v√≠a de optimizaci√≥n para una futura iteraci√≥n "v2.0" del modelo.

---

## üõ†Ô∏è Tecnolog√≠as

| Categor√≠a | Herramientas |
|-----------|--------------|
| **Lenguaje** | Python 3.8+ |
| **ML/NLP** | Scikit-Learn, Gensim |
| **Datos** | Pandas, NumPy, SciPy |
| **Visualizaci√≥n** | Matplotlib, Seaborn, Plotly |
| **Pre-entrenados** | TextBlob, VADER, Transformers (BERT) |
| **Persistencia** | Joblib, Pickle |

### üíª Entorno de Desarrollo

| Componente | Especificaci√≥n |
|------------|----------------|
| **CPU** | Intel Core i9 12¬™ Generaci√≥n |
| **RAM** | 128 GB DDR4 |
| **GPU** | NVIDIA RTX 4080 SUPER (16 GB VRAM) |
| **OS** | Windows |

> **Nota sobre rendimiento:** La GPU fue utilizada principalmente para la comparaci√≥n con BERT/RoBERTa (`09_comparacion_modelos_preentrenados.ipynb`). Los modelos cl√°sicos (SVM, LogReg) se entrenaron en CPU en segundos gracias a la RAM disponible para cargar el dataset completo en memoria.

---

## üìö Referencias

- [Sentiment140 Dataset](http://help.sentiment140.com/for-students)
- [Scikit-Learn Documentation](https://scikit-learn.org/)
- [VADER Sentiment](https://github.com/cjhutto/vaderSentiment)
- [Hugging Face Transformers](https://huggingface.co/docs/transformers)

---

## üìù Licencia

Proyecto acad√©mico - Universidad de Palermo
---

## ‚ö†Ô∏è Archivos No Incluidos (por tama√±o)

Los siguientes archivos superan el l√≠mite de GitHub (100MB) y deben descargarse o regenerarse:

| Archivo | Tama√±o | C√≥mo obtenerlo |
|---------|--------|----------------|
| `data/raw/training.1600000.processed.noemoticon.csv` | ~250 MB | [Descargar de Sentiment140](http://help.sentiment140.com/for-students) |
| `data/processed/train_processed.csv` | ~267 MB | Ejecutar `02_preprocessing.ipynb` |
| `data/vectorized/X_train.pkl` | ~210 MB | Ejecutar `03_vectorizacion.ipynb` |

### Pasos para regenerar:
```bash
# 1. Descargar dataset y colocar en data/raw/
# 2. Ejecutar notebooks en orden:
jupyter notebook notebooks/01_eda.ipynb
jupyter notebook notebooks/02_preprocessing.ipynb
jupyter notebook notebooks/03_vectorizacion.ipynb
```
```
